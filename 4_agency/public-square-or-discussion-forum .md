> - *A certain man of the council rated me the other day in the street about you, sir, but I marked him not; and yet he talked very wisely, but I regarded him not; and yet he talked wisely, and in the street too.*     
> - *Thou didst well: for no man regards it*     
> - *O, thou hast [damnable iteration](https://www.gutenberg.org/cache/epub/1516/pg1516-images.html), and art indeed able to corrupt a saint. Thou hast done much harm upon me, Hal, God forgive thee for it. Before I knew thee, Hal, I knew nothing, and now am I, if a man should speak truly, little better than one of the wicked. I must give over this life, and I will give it over. By the Lord, an I do not, I am a villain. I’ll be damned for never a king’s son in Christendom.*     

- Jupyter books
- Book series
- Embedded webApps
- Personalized risks
- Annotation and dynamic content

## 1

Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton's "ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)" was trained on Nvidias GPUs as
Part of Advances in Neural Information Processing Systems 25 (NIPS 2012). Jensen says this [completely transformed their vision](https://www.youtube.com/watch?v=Sc48ToLIQAY) for Nvidia after 2012. [They](https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\% and 18.9\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.
